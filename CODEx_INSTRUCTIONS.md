# Agentic Job Applications â€” Current Implementation Status

> **System Overview**: A production-ready Slack-first, human-in-the-loop system that automatically discovers new-grad/backend/full-stack roles, scrapes JDs, ranks them using deterministic rules, tracks applications with a clean Slack workflow, and provides infrastructure for cover-letter generation.
> 
> **Current Status**: Core system is fully implemented and operational. Cover letter generation and advanced features are in development.
> 
> **Architecture Principles**:
> * No auto-submit (human approval required)
> * Public pages only (no logged-in scraping)
> * One Slack thread per application
> * Deterministic scoring and ranking

---

## Global Product Specs (canonical across MVPs)

### Slack Channels (fixed)

* `#jobs-feed` â€” periodic digests (new roles + scores) and one-time Needs-Review cards for untrusted domains.
* `#jobs-drafts` â€” an inbox of active cover-letter drafts; each card links back to the correct application thread.
* `#jobs-completed` â€” submissions/archives (used later).

### Schedule

* **Every 3 hours** between **06:00 and 23:00 PT** (inclusive) for discovery + digest posts.

### Target roles (filters)

* **Include** titles with: â€œSoftware Engineerâ€, â€œBackendâ€, â€œBack-Endâ€, â€œFull Stackâ€, â€œFull-Stackâ€, â€œSWEâ€.
* **Include** JDs with: â€œnew gradâ€, â€œentry levelâ€, â€œuniversity gradâ€, â€œgraduateâ€.
* **Do not** penalize â€œ3+ yearsâ€ text.

### Location boosts

* Cities/regions: **New York (NYC)**, **Seattle**, **SF Bay Area** (San Francisco, San Jose, Sunnyvale, Mountain View, Palo Alto, Redwood City, Oakland, Berkeley), **Los Angeles (LA)**, **Irvine / Orange County**.
* +0.10 if location string includes any above.
* +0.05 if **Remote**/**Hybrid** and tied to any above.

### Skills to boost (exact spellings to match)

```
Python, Java, C++, Swift, SQL, MySQL, MongoDB, HTML, CSS, Power BI, Linux,
LangChain, NumPy, CrewAI, Ollama, Streamlit, SQLAlchemy,
Agentic AI, AI Agent, RAG, retrieval-augmented, LLM fine-tuning, multimodal
```

### Trust Gate (v1)

* Signals: domainâ€“brand coherence, ATS provenance (Greenhouse/Lever), TLS/HSTS.
* Verdicts: `auto-safe (>=70)`, `needs-human-approval (40â€“69)`, `reject (<40)`.
* Unseen domains: post one **Needs-Review** card to `#jobs-feed`. **Approve** adds to whitelist.

### â€œAlready applied?â€ rule

* Compute **canonical job id**:

  * Greenhouse: `GH:<job_numeric_id>`
  * Lever: `LEVER:<org>/<slug>` (future)
* Block duplicate **Applications** by canonical id. Warn on near-dupes (same company + similar title + high JD similarity).

### LLM for drafting (MVP-3)

* **Model**: Llama 3.1 8B Instruct (via Ollama or vLLM).
* **Style Card** (inject every time):

  * Tone: compassionate, empathetic, confident, clear
  * Short sentences, 1â€“2 sentence paragraphs
  * **No em dashes, no semicolons**
  * Active voice; mirror **5â€“10%** of the JDâ€™s phrasing only
  * No fabrication of facts/dates/employers; use a concrete metric when available

---

# âœ… MVPart 1 â€” Project Boot + Core Data Contracts (COMPLETED)

**Status**: âœ… **FULLY IMPLEMENTED**

1. âœ… Project structure created (FastAPI + Postgres + Slack client scaffolding)
2. âœ… Complete database schema with all models: `jobs`, `job_sources`, `trust_events`, `whitelist`, `applications`, `artifacts`, `profile_*`, `frontier_orgs`, `digest_logs`, `domain_reviews`
3. âœ… API endpoints implemented for all core functionality

**Data contracts (authoritative)**

* **Job (normalized):**

  ```
  id (uuid), title, company_name, location, url,
  source_type (greenhouse|lever|company),
  domain_root, submission_mode (ats|deeplink),
  jd_text, requirements (jsonb[]), job_id_canonical (string),
  scraped_at (ts), hash (sha1 over title+company+jd_text)
  ```

* **JobSource (raw provenance):**

  ```
  id (uuid), source_type, source_url,
  company_name?, domain_root, raw_payload (jsonb), discovered_at (ts), hash
  ```

* **TrustEvent:**

  ```
  id (uuid), domain_root, url, score (int),
  signals (jsonb[]), verdict (string), created_at (ts)
  ```

* **Whitelist:**

  ```
  domain_root (pk), company_name?, ats_type?, approved_by?, approved_at (ts)
  ```

* **Application (tracker):**

  ```
  id (APP-YYYY-NNN human id + uuid internal), job_id (fk),
  status (Queued|Drafting|Draft Ready|Approved|Submitted|Rejected|Closed),
  slack_channel_id, slack_thread_ts, score (float), canonical_job_id,
  submission_mode, created_at, updated_at
  ```

* **Artifact:**

  ```
  id (uuid), application_id (fk), type (jd_snapshot|cover_letter_vN|autofill_summary|confirmation),
  uri, created_at
  ```

* **Profile (PII + facts):**

  * `profile_identity`: name, preferred_name?, email, phone, base_location
  * `profile_links`: linkedin, github, portfolio
  * `profile_facts`: skills[], tools[], frameworks[], projects[{name, one_liner, metric}], education, work_auth
  * `profile_files`: resume_variants[{label, uri, created_at}]

  > PII encrypted at rest; logs redacted.

**APIs (declare only; implement later)**

* `POST /discover/run` â†’ starts discovery cycle (will be called by scheduler)
* `GET /digest/latest` â†’ returns last runâ€™s top jobs
* `POST /applications/create { job_id }` â†’ creates Application, returns `APP-ID`, Slack thread metadata
* `POST /trust/evaluate { url, company_name? }` â†’ trust verdict
* `POST /trust/whitelist { domain_root, company_name?, ats_type?, approved_by? }`
* `POST /drafts/create { application_id }` â†’ generates CL (MVP-3)
* `POST /drafts/feedback { application_id, feedback_slots{} }` â†’ targeted regen (MVP-3)

**You (human)**

* âœ… Nothing to configure yet.
* âœ… Acceptance: Tables and schemas exist; API contracts documented.

**Tests to create**

* Schema validation tests (Pydantic can roundtrip representative JSON for each model).

---

# âœ… MVPart 2 â€” Seedless Discovery (Open-Source) + JD Scrape + Dedup + Trust (COMPLETED)

**Status**: âœ… **FULLY IMPLEMENTED**

## Intent

âœ… Built a **fully open-source, seedless** discovery engine for **Greenhouse** and **GitHub** that does **not** rely on Google/SerpAPI. The system is architected to **expand** to Lever, Workday, LinkedIn, etc., by adding adaptersâ€”without changing the core pipeline.

## âœ… Implemented Design

* âœ… **Sitemap-based frontier**: Parse `https://boards.greenhouse.io/sitemap.xml` to discover **all** GH org slugs. Seed the **frontier** from this list (stored in DB).
* âœ… **Polite async crawler**: Fetch org **JSON job feeds** (when available) or list pages, then fetch each **job detail page** to extract JD HTML.
* âœ… **Normalization**: Produce `Job` rows with JD text, `requirements[]`, `job_id_canonical = "GH:<numeric_id>"`, and `hash`.
* âœ… **Dedup**: Prefer canonical id; fallback to content hash within a 30-day window.
* âœ… **Trust Gate**: Evaluate domain once; persist `TrustEvent` with Slack integration.
* âœ… **Extensibility**: Use a **SourceAdapter interface** so Lever/Workday extensions can plug in later.
* âœ… **GitHub Integration**: Added SimplifyJobs and New-Grad-2026 adapters for additional job sources.

## âœ… Completed Tasks

1. âœ… **Frontier store (DB)**
   - âœ… Added `frontier_orgs` table with all required fields
   - âœ… Seed step: parse `boards.greenhouse.io/sitemap.xml`, extract `<loc>` ending in `/slug`, and add new slugs (upsert)
   - âœ… Respect robots.txt for `boards.greenhouse.io` (read once per run; cache decision)

2. âœ… **Async fetcher (GreenhouseAdapter)**
   - âœ… Created `services/discovery/greenhouse_adapter.py` with async class
   - âœ… `discover_from_sitemap()` â†’ seeds org slugs
   - âœ… `list_jobs(org_slug)` â†’ returns minimal job refs with JSON feed preference
   - âœ… `fetch_job_detail(url)` â†’ returns JD HTML with normalization
   - âœ… Rate limiting with `aiolimiter` to ~60 req/min across host; timeouts (~5s)
   - âœ… Always use **HTTPS**

3. âœ… **Normalization & fields**
   - âœ… Implemented `services/sources/normalize.py` with:
     - âœ… `html_to_text(html) -> str` (strip tags, collapse whitespace)
     - âœ… `extract_requirements(text) -> list[str]` (heuristics around "Requirements/Qualifications/Responsibilities")
     - âœ… `compute_hash(title, company, jd_text) -> sha1 hex`
   - âœ… Build `job_id_canonical` as `"GH:<id>"` from the detail URL or JSON entry

4. âœ… **Dedup rules**
   - âœ… If `job_id_canonical` seen in last 30 days â†’ skip insert
   - âœ… Else if `hash` seen in last 30 days â†’ skip insert
   - âœ… Else insert **JobSource** + **Job**

5. âœ… **Trust Gate**
   - âœ… Run Trust Gate (v1) per job URL; persist `TrustEvent`
   - âœ… **Slack integration implemented** for domain review workflow

6. âœ… **Extensibility hooks**
   - âœ… Defined `SourceAdapter` protocol/interface in `services/discovery/base.py`
   - âœ… Greenhouse implements it; GitHub adapters added
   - âœ… Added **domain allowlist** to prevent unintended crawling

7. âœ… **Orchestrator endpoint**
   - âœ… Implemented `/discover/run` with:
     - âœ… Ensure frontier is seeded (sitemap parsed at least once)
     - âœ… Pop up to `MAX_ORGS_PER_RUN` orgs by priority/recency
     - âœ… Crawl them, normalize + dedup + trust-evaluate
     - âœ… Return JSON summary: `{ "orgs_crawled": N, "jobs_seen": M, "jobs_inserted": K, "domains_scored": D }`

## Env & Config

Add to `.env` (read via Settings):

```
DISCOVERY_BASE_URL=https://boards.greenhouse.io
DISCOVERY_SITEMAP_URL=https://boards.greenhouse.io/sitemap.xml
DISCOVERY_INTERVAL_HOURS=3
MAX_ORGS_PER_RUN=100
REQUESTS_PER_MINUTE=60
REQUEST_TIMEOUT_SECONDS=5
ALLOWED_DOMAINS=boards.greenhouse.io
```

## Acceptance

âœ… Frontier seeded from GH sitemap (persisted org slugs).
âœ… `/discover/run` crawls up to `MAX_ORGS_PER_RUN` orgs asynchronously and returns a summary JSON.
âœ… Each new job produces a normalized `Job` with: `title`, `company_name`, `location`, `url`, `source_type="greenhouse"`, `domain_root`, `submission_mode="ats"`, `jd_text`, `requirements[]`, `job_id_canonical="GH:<id>"`, `scraped_at`, `hash`.
âœ… Dedup prevents repeats by canonical id, else by hash (30-day window).
âœ… TrustEvents written for domains encountered.
âœ… No external paid APIs used; only HTTPS GETs to public pages; robots.txt respected; rate limiting applied.
âœ… Tests pass (see below).

## Tests

* **Fixtures**:

  * `tests/fixtures/gh_sitemap.xml` (small sample)
  * `tests/fixtures/gh_board_json.json` and/or `gh_board_html.html`
  * `tests/fixtures/gh_job_detail_*.html`
* **Unit**:

  * Sitemap parser extracts slugs correctly.
  * `normalize.html_to_text` and `extract_requirements` behave on small HTML samples.
  * Canonical id parsing `GH:<id>` consistent from URL/JSON.
* **Integration (mocked HTTP)**:

  * End-to-end `/discover/run` inserts jobs; dedup works; returns correct counts.
  * TrustEvent rows written.

## Expected artifacts

```
agentic_jobs/
 â”œâ”€â”€ services/
 â”‚    â”œâ”€â”€ discovery/
 â”‚    â”‚     â”œâ”€â”€ base.py            # SourceAdapter interface
 â”‚    â”‚     â”œâ”€â”€ greenhouse_adapter.py
 â”‚    â”‚     â””â”€â”€ orchestrator.py    # used by /discover/run
 â”‚    â””â”€â”€ sources/
 â”‚          â””â”€â”€ normalize.py
 â”œâ”€â”€ tests/
 â”‚    â”œâ”€â”€ discovery/test_frontier_greenhouse.py
 â”‚    â”œâ”€â”€ sources/test_normalize.py
 â”‚    â””â”€â”€ fixtures/{gh_sitemap.xml, gh_board_json.json, gh_board_html.html, gh_job_detail_*.html}
```

## What you (human) do for MVPart 2

* No API keys required.
* Run `/discover/run` locally (via TestClient or curl) after the part completes.
* Expect: summary output and â‰¥30 unique GH jobs in `jobs` table (given sample fixtures + a limited real run if desired).
* Verify: dedup honored; TrustEvents created; **no Slack posts yet**.

---

# âœ… MVPart 3 â€” Slack Digest + Needs-Review + Tracker Threads (COMPLETED)

**Status**: âœ… **FULLY IMPLEMENTED**

## âœ… Completed Objectives

1. âœ… Implemented the **3-hour scheduler** (06:00â€“23:00 PT) with configurable time windows
2. âœ… After discovery, **rank** the newly ingested jobs with deterministic rules
3. âœ… Post a **digest** to `#jobs-feed`: compact rows (Title Â· Company Â· Location Â· **Score chip**), actions: **Open JD**, **Save to Tracker**
4. âœ… For **unknown domains**, post a **Needs-Review** card with Approve/Reject; approving writes to `whitelist`
5. âœ… **Save to Tracker** creates an **Application** and starts a **Slack thread** with header message containing job details + score + canonical id + status `Queued`

**Slack UX rules**

* **One thread per Application**; all future CL activity for that job stays in that thread.
* Digest is **periodic**; it should not spam duplicates.
* Needs-Review is **once per domain** (until approved/rejected).

**You (human)**

* Provide **Slack bot token**, **signing secret**, **channel ids** (or channel names).
* Invite the bot to channels.
* Acceptance: Every 3 hours you see a digest with score chips. Clicking **Save to Tracker** creates a thread with APP-ID, and unknown domains trigger a one-time Needs-Review card. Approve adds to whitelist.

**Tests**

* Mock Slack client in unit tests.
* Integration test: simulate a set of new jobs, confirm digest rows rendered, confirm thread creation on Save to Tracker.

---

# âœ… MVPart 4 â€” Deterministic Ranking (Skills + Geo Boosts) (COMPLETED)

**Status**: âœ… **FULLY IMPLEMENTED**

## âœ… Completed Objectives

1. âœ… Implemented the **rules engine** for scoring (no embeddings) in `services/ranking/scorer.py`
2. ğŸ”„ Expose a `rank.yaml` config to tune weights without code changes (planned for future enhancement)
3. âœ… Return `score` and a concise **rationale** string for each job ("new grad + backend + Python + SF Bay (remote)")

**Default weights (can be stored in `rank.yaml`)**

* Title match: **+0.15** if title contains â€œSoftware Engineerâ€, â€œBackendâ€, â€œBack-Endâ€, â€œFull Stackâ€, â€œFull-Stackâ€, â€œSWEâ€.
* New-grad phrases: **+0.20** if JD contains â€œnew gradâ€, â€œentry levelâ€, â€œuniversity gradâ€, â€œgraduateâ€.
* Skills (search JD text, case-insensitive):

  * Python (+0.08), Java (+0.07), C++ (+0.06), Swift (+0.05), SQL/MySQL (+0.05), MongoDB (+0.04),
  * HTML/CSS (+0.03), Linux (+0.03), Power BI (+0.03),
  * LangChain (+0.05), NumPy (+0.04), SQLAlchemy (+0.04), Streamlit (+0.04), CrewAI (+0.04), Ollama (+0.04),
  * Agentic AI / AI Agent / RAG / retrieval-augmented / LLM fine-tuning / multimodal (+0.05 each; cap combined at +0.10).
* Location boosts:

  * **+0.10** if location mentions any: NYC, Seattle, SF Bay (San Francisco, San Jose, Sunnyvale, Mountain View, Palo Alto, Redwood City, Oakland, Berkeley), LA/Los Angeles, Irvine/Orange County.
  * **+0.05** if Remote/Hybrid **and** tied to any above (e.g., â€œRemote (US) â€” SF/Bay Area preferredâ€).
* **No penalty** for â€œ3+ yearsâ€.
* Clamp final score to **[0,1]**.

**You (human)**

* Confirm the list of geo names is correct; you can update `rank.yaml` any time.
* Acceptance: Digest ordering makes sense; top 10 clearly better than bottom 10; rationale reads well.

**Tests**

* Synthetic JDs: verify each keyword and geo contributes the expected delta.
* Rationale builder tests.

---

# ğŸ”„ MVPart 5 â€” Cover-Letter Drafting (LLM) + Organized Review (IN DEVELOPMENT)

**Status**: ğŸ”„ **PARTIALLY IMPLEMENTED** (Database models and API stubs exist, LLM integration pending)

## ğŸ”„ Current Status

1. ğŸ”„ Stand up an **LLM runner** (local) for **Llama 3.1 8B Instruct** via **Ollama** or **vLLM** (planned)
2. ğŸ”„ Implement **DraftPackage** generation and a **slot template** prompt using the **Style Card** (planned)
3. ğŸ”„ In an Application thread, add button **Generate Cover Letter** â†’ produce **CL v1** and post it **in the thread** and mirror a compact card to `#jobs-drafts` (planned)
4. ğŸ”„ Add **Request changes** â†’ Slack modal with structured fields (short free-text allowed). Regenerate **only affected slots** (CL v2, v3, â€¦). Pin the latest in the thread; store previous versions as artifacts (planned)

## âœ… Completed Infrastructure

- âœ… Database models for `Artifact` and `Application` with cover letter support
- âœ… API endpoint stubs in `drafts.py` and `feedback.py`
- âœ… Slack integration infrastructure ready for cover letter workflow

**Style Card (inject on every generation)**

* Tone: compassionate, empathetic, confident, clear
* Short sentences; 1â€“2 sentence paragraphs
* **No em dashes; no semicolons**
* Active voice; mirror **5â€“10%** of JD phrasing
* No fabrication of facts; prefer one concrete metric
* Personal themes **when relevant**: mental-health/brain modeling motivation; growth mindset with structured work habits

**Slot Template (sections)**

* Opener (your voice)
* Why Company (2 bullets; JD-anchored)
* Role Alignment (2â€“3 bullets; JD â†’ your skills)
* Impact Snapshot (2â€“3 bullets from: RAG eval, anomaly detection, exec reporting)
* First 60â€“90 Days (3 realistic, JD-tailored goals)
* Stack Summary (subset of your stack, tuned to JD)
* Close + Signature

**JSON input contract to the model (canonical)**

```json
{
  "app_id": "APP-2025-000123",
  "role": { "title": "...", "company": "...", "location": "..." },
  "job_url": "...",
  "jd": {
    "summary": "...",
    "bullets": ["...","..."],
    "phrases": ["..."],
    "tone_sample": "..."
  },
  "profile": {
    "identity": { "name": "Apoorva Chilukuri" },
    "skills": [...],
    "projects": [
      {"name":"RAG Eval Harness","one_liner":"...","metric":"..."},
      {"name":"Anomaly Detection","one_liner":"...","metric":"..."},
      {"name":"Exec Reporting","one_liner":"...","metric":"..."}
    ],
    "stack": ["Java","Python","SQL","TypeScript/React (learning)", "REST/gRPC basics", "Linux/CLI", "Docker basics", "Git/GitHub", "JUnit/PyTest", "GitHub Actions/CI", "logging & metrics", "A/B testing", "JSON/HTTP APIs", "code review", "clear docs"]
  },
  "style_card": { "tone": ["compassionate","empathetic","confident","clear"], "rules": ["short sentences","no em dashes","no semicolons","active voice","mirror 5-10% JD","no fabrication"] },
  "slots": {
    "opener_hint": "Tie interest to product/mission; 1 fit signal",
    "why_company": ["reason_1","reason_2"],
    "role_alignment_targets": ["backend","APIs","SQL","AWS"],
    "impact_picks": ["RAG eval","anomaly detection","exec reporting"],
    "plan_hints": ["own a small service/API","instrumentation + metrics","a targeted experiment/readout"],
    "stack_focus": ["Java","Python","SQL","REST/gRPC","Docker basics"]
  }
}
```

**Model output**

```json
{
  "version": "CL v1",
  "cover_letter_md": "Dear Hiring Manager,\n...\nApoorva Chilukuri",
  "sections_used": ["opener","why_company","role_alignment","impact","plan","stack","close"],
  "provenance": { "why_company": ["jd.phrases[0]"], "role_alignment": ["profile.skills[*]"], "impact": ["profile.projects[*]"] }
}
```

**Slack UX rules**

* **All** CL versions live **inside the Application thread**.
* `#jobs-drafts` contains a **compact card** per active draft that links back to the thread and provides Approve/Request-changes/Discard buttons.
* Regens replace the **pinned** version and archive the previous as an artifact.

**You (human)**

* Provide 2â€“3 writing samples (done).
* Confirm Llama 3.1 8B is installed and can be served locally.
* Acceptance: For multiple active Applications, you can generate, request targeted edits, and approve CLs without any thread mixing; style rules are respected (no em dashes; no semicolons).

**Tests**

* Unit tests for prompt assembly (no PII leak).
* Golden test: deterministic seed producing stable section structure.
* Slack modal plumbing tests (action payloads route to correct application thread).

---

# âœ… MVPart 6 â€” Operational Details (Scheduler, Idempotency, Observability) (COMPLETED)

**Status**: âœ… **FULLY IMPLEMENTED**

## âœ… Completed Objectives

1. âœ… Implemented scheduler windows (06:00â€“23:00 PT) with **3-hour cadence**; idempotent runs (don't repost the same jobs)
2. âœ… Logging: structured JSON; redact PII; include `app_id` / `job_id` in log contexts
3. âœ… Metrics counters (even simple logs): jobs_seen, jobs_new, digest_rows_posted, domains_review_posted, applications_created, drafts_generated

**You (human)**

* Verify digests do not repost identical items within the same day; check logs for counters.
* Acceptance: predictable cadence; no duplicate noise; clear counters in logs.

---

## âœ… Current System Status

### **Fully Operational**
* âœ… **Job Discovery**: Automatic discovery from Greenhouse and GitHub sources
* âœ… **Slack Integration**: Interactive components, digests, and application tracking
* âœ… **Trust System**: Domain review and whitelist management
* âœ… **Application Tracking**: Complete lifecycle from discovery to submission
* âœ… **Scoring System**: Deterministic job ranking with rationale

### **In Development**
* ğŸ”„ **Cover Letter Generation**: LLM integration for automated cover letter drafting
* ğŸ”„ **Advanced Features**: Enhanced ranking, profile management, additional data sources

## What you (human) need to do

* **Secrets & config**: Provide Slack bot token, signing secret, channel ids (or names)
* **Review cadence**: Expect digests **every 3 hours** in `#jobs-feed`. Approve any new domains once; click **Save to Tracker** on roles you want to pursue
* **Application management**: Use Slack threads to track applications, approve domains, and manage the job application process

---

## Questions / Info Codex may need to ask you during build

* **Search provider**: Confirm which search API to use for seedless GH discovery (SerpAPI or Programmable Search). Provide API key if needed.
* **Slack workspace**: Are the channel names exactly `#jobs-feed`, `#jobs-drafts`, `#jobs-completed`? If different, provide the exact names/ids.
* **Allow/deny list**: Any companies you want always included or excluded?
* **Artifacts storage**: For MVPs, local disk is fine. If you prefer S3/minio now, provide bucket credentials.
* **PII**: Provide your profile facts (skills list above is great), links, and resume PDF(s) so the tracker and drafts have accurate info.

---

### Final note for Codex

* Keep **idempotency** everywhere (dedup by canonical id and hash).
* Keep **safety**: never automate behind logins; never submit forms; never store secrets in logs.
* Keep **organization**: one **Application â†’ one Slack thread**; mirror only small cards in `#jobs-drafts`.
* Implement **tests per MVPart** before moving on.

